---
title: "Variational Autoencoders for Collaborative Filtering"
date: 2024-10-13
categories: [Paper_review,EN]
tags: [autoencoders,variational inference, collaborative filtering]
toc: true
toc_label: "Table of contents"
toc_icon: "cog"
math: true
---

**Disclaimer**
This blog post is a summary of what I understood reading the paper. This is for personal use and might contain wrong information.

---

I am introducing Mult-VAEs only. Mult-DAEs is ommited in this review.
# Abstract

VAEs, unlike linear factor models that still dominate collaborative filtering research, is a non linear probabilistic 
model. VAE is a generative model with multinomial likelihood and associated with bayesian inference. Also, the paper 
introduces a different regularization parameter, which ultimately leads to better performance. It is empirically shown
the VAEs outperforms the SOTA baselines including neural network based models.

# Introduction

Collaborative filtering is one of the most frequently adopted approaches in recommender systems by predicting 
certain users' preferences by examining similar patterns between users and items. Latent factor models are traditional
methods, but the models are linear, limiting modeling capacity. There have been efforts to apply neural networks to the collaborative
filtering and the paper extends variational autoencoders to collaborative filtering with implicit feedback.

VAEs, with the help of neural networks, enables us to explore non linear probabilistic latent factor models and 
the paper proposes a model with multinomial likelihood. Ranking based metrics are often utilized to evaluate prediction in recommendation systems.
However, Top-N ranking loss is hard to be directly optimized and authors argue that multinomial likelihoods are better suited for implicit feedback data
compared to widely used likelihood functions such as Gaussian and logistic.

Recommendation problems are often treated as **big data** problems, but authors argue that they are **small data** problems, based on the fact
that recommendation data are often sparse, and bayesian approaches are optimal to deal with the inherent problems.

## Method

The model learns implicit feedback data, specifically clicks in this paper. 

### Model

It is assumed that for each user u, K-dimensional $z_{u}$ is sampled from a standard Gaussian. 

$z_u \sim \mathcal{N}(0, I_K), \quad \pi(z_u) \propto \exp\{f_\theta(z_u)\}, \quad x_u \sim \text{Mult}(N_u, \pi(z_u))$ 

Then, $z_u$ is further transformed via a non linear function $f_{\theta} \in R^{I}$, resulting in a pmf over I items, from which the click history $x_{u}$ will be drawn from.
Thus, the log-likelihood for user u is represented as 
$\log p_{\theta} (x_{u} | z_{u}) = \sum_{i} x_{ui} \log \pi_ {i} (z_{u})$
,which is a multinomial likelihood as explained above and the multinomial likelihood encourages the model to put probability mass on non-zero entires in $x_{u}$. And, since 
probability mass has to sum up to 1, the items are allocated probabilities from limited budget. So, the authors argue that the model is better suited for the top-N ranking loss than other loss functions.

### Variational inference

The main goal of generative models is to estimate the parameter $\theta$. To estimate $\theta$, one needs to approximate posterior distribution $p(z_{u} | x_{u})$ first. Variational inference approximates the posterior with a variational
distribution $q_{z_{u}}$. And, it is assumed that $q$ follows a gaussian with mean $\mu_{u}$ and covariance matrix diagnoal with $\sigma^2_{u}$. And, the objective is to minimize KL divergence $\text{KL}(q(\mathbf{z}_{u})\parallel p(\mathbf{z}_u \mid \mathbf{x}_{u}))$.
ELBO enables us to iteratively maximize the log likelihood, but the problem is that one cannot optimize gradients with respect to $\phi$ since $\phi$ is a parameter for the distribution. The problem can be avoided by the reparameterization trick by sampling $\epsilon$ from 
$N(0,I_{K})$ and $z_{u}$ is reparameterized as $\mathbf{z}_u = \mu_\phi(\mathbf{x}_u) + \epsilon \odot \sigma_\phi(\mathbf{x}_u)$. 

In the paper, authors argue that ELBO can be interpreted from a different perspective: The first term is a reconstruction error term and the second KL term to be a regularization term. So, by introducing a parameter $\beta$ in front of the KL term, we can control to what extent
we want to regularize the likelihood function. And, by selectign $\beta$ to be less than 1, by sacrificing the generative ability, we can more accurately restore the latent factor matrix, which is what we desire to do in modeling.

![image](https://github.com/user-attachments/assets/7f6e3094-df9b-4186-a5d4-45c44fdda632)

By using autoencoders, encoders and decoders can derive inference and generative models. 

## Result

Three datasets have been used for comparison between baselines. VAE significantly outperformed other SOTA baselines as shown below.

![image](https://github.com/user-attachments/assets/3bc43f10-4860-4d60-9d06-92c5b2ffaf69)

## Thoughts upon reading the paper

Upon reading the paper, I was impressed by the idea of introducing a regularization parameter $\beta$ to control to what extent the model needs to be regularized. With respect to generative models, it will imply that we are sacrificing the distributive attribute, 
losing explainability in the process. But, since we do not know what latent factors contribute to the preferences of users in items, the goal to have a completely generative model would have been impossible. Nevertheless, since the authors prioritized reconstruction first, 
I was curious as to whether we can increase explainability in our model sacrificing accuracy, leading to trustability in prediction.
