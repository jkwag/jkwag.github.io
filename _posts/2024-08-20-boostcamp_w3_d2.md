---
title: "네이버 부스트캠프 3주차 1일 차 회고"
date: 2024-08-20
categories: [Boostcamp,3주차]
tags: [boostcamp,data scientist,visualization, eda]
toc: true
toc_label: "Table of contents"
toc_icon: "cog"

---

3주차가 시작되었다. 2주차 마지막날은 할 일을 다 끝내고 개인 공부, 조별 공부를 진행하느라 회고를 쓰지 않았고 3주 1일 차 회고에 묶어서 쓰기로 했다. 3주차의 테마는 **EDA** 그리고 **Data visualization** 인데 쉬운 것 같아 보이면서도 진행하면서 예상치 못하게 소중한 insight를 얻을 수 있기에
주의깊게 진행해야 되는 과정이라 생각하고 강의에서도 이러한 부분이 강조되었다. 첫 강의는 비즈니스에서 **Data Scientist** 를 비롯한 Data 직무가 비즈니스에서 가지는 가치와 어떻게 비즈니스에 기여를 할 수 있는지에 대한 부분인데 인상 깊게 들었고 이 대목에도 글을 진행하면서 다뤄보겠다.
___
# 월요일 피어세션

월요일 피어세션에서는 읽기로 했던 논문 **matrix factorization techniques** for recommender systems 를 팀원들과 함꼐 리뷰했다. 조금 오래된 논문이지만 recsys 도메인에서 기본으로 쓰였던 모델인만큼 읽으면서 인상이 깊었고 팀원들도 그 부분에 공감을 했다. 주로 얘기됐던 부분은 user-item matrix는
sparse 하기 때문에 matrix를 3개로 분해하는 SVD 가 불가능하다는 점, 그러기 때문에 user-latent factor, item-latent factor 두 개로 분해하면서 regularization term들을 추가해 overfitting을 방지했다는게 핵심 내용으로 거론되었고 결과적인 부분에서는 temporal effect가 가장 컸다는 것.
그러나 논문에서는 이러한 function term들을 b(t), q(t) 이런식으로 정확히 temporal effect가 어떻게 반영됐는지에 대한 부분이 생략되었기에 아쉬웠다. 또한, **트랜스포머** 구조서 encoder 와 decoder 부분에 대해 제대로 아직 숙지되지 못한 듯 하여 팀원들에게 질문하면서 설명하려 하였고 이 부분에서 부족한 점을 발견하여
다시 공부할 필요성을 느끼고 이번 주 안에 다시 볼 계획이다.

# 월요일 계획 및 개인 공부

개인공부를 혼자서 하니까 동기부여가 잘 생기는 것 같지 않아 팀원들과 개인 공부 계획을 서로 공유하고 주간의 마지막에 서로의 진행상황을 체크하기로 했다. 나는 주로 알고리즘과 코딩 테스트 준비가 개인 공부의 주이고 이를 팀원들에게 알렸다. 월요일에 개인 공부 할 여유가 꽤 많았는데 알고리즘 공부를 하던 도중
그래프 이론이 부족하다는 생각이 들었고 그래프 이론 보충이 개인 공부 최우선 과제가 되었다. 코딩 테스트 문제는 일주일에 최소 3 개 풀기가 목표이다.

# 화요일 3주차 시작

시작은 Data scientist 를 비롯해서 Data 라는 것이 비즈니스에서 어떠한 목표를 가지고 데이타를 분석할지 초점을 두라는 조언으로 첫 강의가 시작됐다. 과거에는 데이타를 통계를 바탕으로 **추론**이 주였지만 최근에는 **해석**, **의사결정**, 그리고 **예측**이 데이타의 유형도 다양해지고 사이즈가 커짐에 따라 주로 기업들이
데이타로부터 얻고자 하는데 의사 결정이란 부분에 있어서 Data가 꼭 주요 지표가 아니고 보조 지표로도 활용될 수 있다고 설명되었다. 또한, 데이타의 한계도 지적이 되었는데 주로 리소스 부족, 데이타 만능론 등이 거론되었는데 이러한 점은 내가 프로젝트를 진행하면서도 느꼈는데 일례로 에어비엔비 데이타를 가지고 분석할 때  
경제적 지표와 관련된 문제를 정의하고 프로젝트를 시작했으나 데이타를 찾기도 힘들고 데이타가 분석에 적합한 형태가 아니라 고생했던 기억이 있다. 그리고, 좋은 질문과 EDA는 함꼐 간다는 부분도 거론되었는데 좋은 질문이 있다면 EDA를 진행하면서 insight를 얻기 위해 집중해야 되는 부분, 그리고 방법론에 대해서도 뚜렷하게 결정되기에
이 부분에 공감이 갔다. 데이타 직무의 결론은 결국에 **interest group** 설득하기인데 이번 주 주요 테마인 data visualization과 관련해 설명하려는 대상이 누구인가 고려해야 된다가 중요하다고 생각했다.(엔지니어와 엔지니어링 지식이 다소 떨어지는 결정단의 사람들 차이)

## 데이타
그 다음 강의는 데이타가 무엇인지 정의를 하고 시작했다. 사전적 의미로는 데이타란 의사 결정에 도움을 줄 수 있는 컴퓨터가 사용, 저장 가능한 정보 유형이나 데이타는 **가정**, **수집 방법**, **해석**에 따라 달라질 수 있다. 따라서, 도메인에 따라 형태가 다양하게 나타나고 (ex. 정형 데이타, 시계열 데이타) 이에 따라
적절한 시각화 방법도 달라진다.


## 시각화

시각화에서는 두 가지 요소가 강조되는데 가진 정보를 모두 포함할 수 있어야 하고 중요한 부분이 강조되어 의미가 지표를 보는 사람에게 전달 될 수 있어야 하는데 그만큼 시각화 방법에 따라 잘못된 정보를 전달할 수 있다는 점도 강조됐다.
또한 시각화 원칙에는 5가지로 요약될 수 있는데
- Accuracy
- Discriminability
- Separability
- Popout
- Grouping
데이타 간 구분이 명확해야 된다는 점이 강조됨을 알 수 있다.
이후 시각화를 할 수 있는 여러가지 방법이 소개되었다.
### Bar plot
Bar plot은 범주에 따른 수치 값을 비교하기에 적합한 방법인데 이는 개별간의 비교 그리고 그룹간의 비교에 유용하다. 가로로 쌓는 방법, 그리고 세로로 쌓는 방법이 소개됐는데 기본적으로 7개 이상의 그룹은 구분하기 쉽지 않기 때문에 추천하지 않는다고 거론됐다

![bar plot](https://matplotlib.org/stable/_images/sphx_glr_bar_colors_001_2_00x.png)

### Line plot

Line plot은 연속적으로 변하는 데이타(점)을 선으로 연결한 그래프인데 시간/순서에 대한 변화, 즉 시계열 데이타 분석에 특화되어 있다. 그래프를 그렸을 떄 노이즈가 많아 시각적 해석을 방해할 때 Moving average 기법을 통해 smoothing을 할 수 있다.

![line plot](https://wac-cdn.atlassian.com/dam/jcr:526dfc9b-3950-49a8-afcd-fd37ee59782a/line-chart-example-1.png?cdnVersion=2154)

### Scatter plot

Scatter plot 은 기본적으로 x축, y축의 feature 값에 따라 점의 형태로 데이타가 표시되는데 x축,y축의 feature간 비교에 용이하다. 따라서, 상관관계를 알기 쉬운데 이 때 상관관계와 인과관계를 혼동하는 경우가 있으니 주의해야하는데 인과관계는 도메인 지식을 바탕으로 가정이 들어간다.

![scatter plot](https://wac-cdn.atlassian.com/dam/jcr:ec88db6d-cf1f-450e-8557-d24c3ef15a39/scatter-plot-example-1.png?cdnVersion=2154)

## 정형 데이타

정형 데이타는 범주형 데이타, 수치적 데이타로 나눠질 수 있다.

### 범주형 데이타

범주형 데이타는 **순서형**과 **명목형 데이타**로 나눠서 설명할 수 있는데 실제 프로젝트서 commute의 형태 중 버스/차/걷기 등 명목형 데이타로 표현해야 되는 부분에서 순서형으로 매핑했다 해석이 애매해졌던 경험이 수업을 듣는 도중 생각났었다. 즉, 명목형 데이타는 순서가 없고 순서형은 순서가 있다고 얘기할 수 있는데 집단을 비교하기 위해
평균, 최빈값, 중앙값 등으로 대푯값으로 EDA가 들어가는데 어떠한 지표를 정할지는 도메인 지식이 우선시 되어야 한다. 좋은 일례로는 노스캐롤라이나 대학교 지리학과 평균 소득이 다른 대학교 지리학과에 비해 훨씬 높을텐데 이는 마이클 조던이라는 아웃라이어가 존재하기 때문에 평균이라는 지표가 그룹의 데이타를 대표한다고 보기 힘들것이다. 명목형
데이타를 전처리 하는 방법에 One hot encoding 이 소개되었는데 통계에서 배운 Dummy variable 과 구조가 비슷해 익숙했다. 특정 값에 따라 인코딩을 하는 방법도 소개되어 값을 그룹을 인코딩하는단에서 사용해 효율을 증가시킬 수 있다 설명되었는데 캐글서 활발히 사용된다는 얘기를 들으니 나중 프로젝트서 실제 사용해 봐야겠다는 생각이 들었다.

### 수치적 데이타

수치적 데이타는 **이산형**과 **연속형**으로 나눠 설명할 수 있는데 이산형은 일반적으로 정수 형태를 띄고 있고 연속형은 실수 형태를 띄고 있다. 이들의 대푯값은 같더라도 분포는 굉장히 상이할 수 있는데 이를 해결하기 위한 전처리로는 **정규화**와 **표준화**가 있다. 정규화는 전체 데이타를 지정한 특정 범위 예를 들어 [0,1]로 변환하고 표준화는
평균을 0 표준편차를 1로 만들어 데이타를 표준 정규 분포화 시킨다. 또, Box-Cox transformation이라는 x를 $/lambda$에 따라 여러가지 형태로 변환시키는 방법이 있는데 이는 도메인 지식을 따라 결정하게 된다.






